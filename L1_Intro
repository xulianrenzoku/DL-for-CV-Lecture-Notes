Michigan Online
Deep Learning for Computer Vision
Instructor: Justin Johnson

Lecture 1: Introduction to Deep Learning for Computer Vision

- CV definition: Building artificial systems that process, perceive, and reason about visual data
    - Don’t care how you do it
    - Teach machine to see
- Learning: Building artificial systems that learn from data and experience
    - Try to build systems that adapt
    - Teach machine to learn
- Deep Learning: Hierarchical learning algorithms with many “layer”, (very) loosely inspired by the brain

Today’s Agenda
- A brief history of CV and DL
- Course overview & logistics

**History of CV**
- Hubel and Wiesel, 1959
    - Study about how cells work
    - Cat experiment, make it watch TV, and record its reaction
    - JJ thinks it is the beginning of CV
- Larry Roberts, 1963
    - PhD of MIT
    - First thesis about computer science
    - Detecting Edges are fundamental
- Seymour Papert, 1966
    - The Summer Vision Project
- David Marr, 1970s
    - Stages of Visual Representation
    - Input image —> Edge image —> 2.5D sketch —> 3D model
- Recognition via Parts
    - Generalized Cylinders
    - Pictorial Structrures
- Recognition via Edge Detection (1980s)
    - John Canny, 1986
    - David Lowe, 1987
- Recognition via Groupings (1990s)
    - Normalized Cuts, Shi and Malik, 1997
- Recognition via Matching (2000s)
    - SIFT, David Lowe, 1999
- Face Detection
    - Viola and Jones, 2001
    - One of the first successful applications of ML to vision
    - Boost of decision trees
    - Fast commercialization (digital cameras)
- PASCAL Visual Object Challenge
    - Mean average precision increased by years (2005-2011)
- ImageNet 
    - Large Scale Visual Recognition Challenge
    - Crowdsourcing labeling to people around the world
    - Benchmark challenge (“Olympics of CV”)
    - 2012: Enter DL (Major breaktrhough)
        - Error rate dropped from 25.8 —> 16.4
- AlexNet: DL Goes Mainstream (2012)
    - Krizhevsky, Sutskever, and Hinton, NeurlPS 2012

**History of DL**
- Perceptron, 1958
    - One of the earliest algorithms that could learn from data
    - Implemented in hardware
    - Could learn to recognize letters of the alphabet
    - Today we would recognize it as a linear classifier (will be introduced in later lectures)
- Minsky and Papert, 1969
    - Showed that Perceptrons could not learn the XOR function (will be introduced in later lectures)
    - Made people lose interest in the field
    - Introduce the conception of multi-layer perceptrons (lost attention in mainstream)
- Neocognitron: Fukushima, 1980
    - Computational model the visual system, directly inspired by Hubel and Wiesel’s hierarchy of complex and simple cells
    - Interleaved simple cells (convolution) and complex cells (pooling)
    - Looks a lot like AlexNet (more than 32 years later)
    - No practical training algorithm
- Backprop: Rumelhart, Hinton, and Williams, 1986
    - Introduced backpropagation for computing gradients in neural networks
    - Successfully trained perceptrons with multiple layers
- Convolutional Networks: LeCun et al, 1998
    - Applied backprop algorithm to a Neocognitron-like architecture 
    - Learned to recognize handwritten digits
    - Was deployed in a commercial system by NEC, processed handwritten checks
    - Very similar to our modern convolutional networks
- “Deep Learning”, 2000s
    - People tried to train neural networks that were deeper and deeper
    - Not a mainstream research topic at this time
- AlexNet (2012)
- 2012 to Present:
    - Deep Learning Explosion
    - ConvNets are everywhere
        - Image Classification
        - Image Retrieval
        - Object Detection
        - Video Classification
        - Pose Recognition
        - Playing Atari games
        - Medical Imaging
        - Whale recognition
        - Galaxy Classification
        - Image Captioning
        - Art Generating

Why explode in 2012? JJ’s take:
- Algorithms
- Data
- Computation
    - Development of GPU

** Course overview and logistics **
- 6 programming assignments
    - Python
    - PyTorch
    - Google Colab

Course Philosophy
- Thorough and Detailed
    - Understand how to write from scratch, debug, and train convolutional and other types of deep neural networks
    - We prefer to write from scratch, rather than rely on existing implementations
- Practical
    - Focus on practical techniques for training and debugging neural networks
- State of the art
- Will also cover some fun topics
    - Image captioning (with RNNs)

Course Structure
- First half: Fundamentals
    - Details of how to implement and train different types of networks
    - Fully-connected networks, convolutional networks, recurrent networks
    - How to train and debug, very detailed
- Second half: Applications and “Researchy” topics
    - Object detection, image segmentation, 3D visions, videos
    - Attention, Transformers
    - Vision and Language
    - Generative models: GANs, VAEs, etc
    - Less detailed: provide overview and references, but skip some details









